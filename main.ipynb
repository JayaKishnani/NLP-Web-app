{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "77a48715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import tensorflow_addons as tfa\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b6b6229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "76b777c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['JAVAHOME'] =  \"C:\\Program Files\\Java\\jdk-18.0.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dcaa25c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils import text_file\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "from tkinter import ttk\n",
    "from PIL import ImageTk, Image\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_tkagg import (FigureCanvasTkAgg, NavigationToolbar2Tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f9926b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "count = []\n",
    "def detect_sentiment():\n",
    "    text = textArea.get(\"1.0\",\"end\")\n",
    "    #file_in = open(filename, 'r')\n",
    "    lines = text.split('.')\n",
    "    lines.pop()\n",
    "    count1, count2, count3 = 0,0,0\n",
    "    for line in lines:\n",
    "        #sentence = textArea.get(\"1.0\", \"end\")\n",
    "        sa = SentimentIntensityAnalyzer()\n",
    "        sentiment_dict = sa.polarity_scores(line)\n",
    "        #sentiment as positive, negative and neutral\n",
    "        if sentiment_dict['compound'] >= 0.05 :\n",
    "            string = \" Positive \"\n",
    "            count1+=1\n",
    " \n",
    "        elif sentiment_dict['compound'] <= - 0.05 :\n",
    "            string = \" Negative \"\n",
    "            count2+=1\n",
    "      \n",
    "        else :\n",
    "            string = \" Neutral \"\n",
    "            count3+=1\n",
    "        results.append(string)\n",
    "        result_area.insert(END, string+'\\n')\n",
    "    count.append(count1)\n",
    "    count.append(count2)\n",
    "    count.append(count3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70f1678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_txt():\n",
    "    text_file = filedialog.askopenfilename(initialdir=\"C:/Users/HP/Desktop/Project/\", title=\"Select a file\", filetypes=[('text files','*.txt')])\n",
    "    text_file = open(text_file, 'r')\n",
    "    stuff = text_file.read()\n",
    "    textArea.insert(END, stuff)\n",
    "    #text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d429266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ner_prediction():\n",
    "    model = load_model('ner_model.h5', custom_objects={\"crf\":tfa.layers.CRF})\n",
    "    tags = ['B-gpe', 'I-org', 'I-gpe', 'I-tim', 'O', 'I-art', 'I-nat', 'I-eve', 'I-geo', 'B-art', 'B-per', 'B-org', 'B-eve', 'B-geo', 'B-nat', 'I-per', 'B-tim']\n",
    "    text = textArea.get(\"1.0\",\"end\")\n",
    "    words = list(set(text.split())) \n",
    "    word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
    "    word2idx[\"UNK\"] = 1 # Unknown words\n",
    "    word2idx[\"PAD\"] = 0 # Padding\n",
    "    idx2word = {i: w for w, i in word2idx.items()}\n",
    "    max_len = 75\n",
    "    x = {}\n",
    "    \n",
    "    pad_line = pad_sequences(sequences=[[word2idx.get(w, 0)] for w in word_tokenize(text)], padding=\"post\", value=0, maxlen=max_len)\n",
    "    for i in range(len(pad_line)):\n",
    "        p = model.predict(np.array([pad_line[i]]))\n",
    "        p = np.argmax(p, axis=-1)\n",
    "        for w, pred in zip(pad_line[i], p[0]):\n",
    "            x[w] = tags[pred]\n",
    "    y = {}\n",
    "    for num in list(x.keys()):\n",
    "        y[idx2word[num]] = x[num]\n",
    "                \n",
    "    result_area.insert(END, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79a9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf1a3c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ner_res = []\n",
    "def stanford_ner():\n",
    "    from nltk.tag import StanfordNERTagger\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    st = StanfordNERTagger('D:\\stanford-ner-4.2.0\\stanford-ner-2020-11-17\\classifiers\\english.all.3class.distsim.crf.ser\\english.all.3class.distsim.crf.ser',\n",
    "                          'D:\\stanford-ner-4.2.0\\stanford-ner-2020-11-17\\stanford-ner.jar',\n",
    "                          encoding='utf-8')\n",
    "    nltk.download('punkt')\n",
    "    text = textArea.get(\"1.0\",\"end\")\n",
    "    lines = text.split('.')\n",
    "    lines.pop()\n",
    "    for line in lines:\n",
    "        tokenized_text = word_tokenize(text)\n",
    "        classified_text = st.tag(tokenized_text)\n",
    "        #ner_res.append(classified_line)\n",
    "        result_area.insert(END, classified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a552880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_it():\n",
    "    fig = Figure(figsize = (2, 2), dpi = 100)\n",
    "    fig.add_subplot(111).pie(count)\n",
    "    canvas = FigureCanvasTkAgg(fig, master = gui)  \n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().grid(row = 5, column = 1, pady = 2)\n",
    "    #toolbar = NavigationToolbar2Tk(canvas, gui)\n",
    "    #toolbar.update()\n",
    "    #canvas.get_tk_widget().grid(row = 5, column = 1, pady = 2)\n",
    "    #plt.figure()\n",
    "    #plt.pie(count)\n",
    "    #plt.legend(['Positive', 'Negative', 'Neutral'])\n",
    "    #plt.show(block = False)\n",
    "    \n",
    "def clear_all():\n",
    "    textArea.delete('1.0', END)\n",
    "    result_area.delete('1.0', END)\n",
    "\n",
    "def save_file():\n",
    "    saved_file = open('C:/Users/HP/Desktop/Project/results.txt', 'w')\n",
    "    saved_file.write(result_area.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "84253cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    gui = tk.Tk()\n",
    "    gui.geometry(\"700x700\")\n",
    "    gui.title(\"NLP App\")\n",
    "    gui.configure(bg=\"purple\")\n",
    "    result_var = tk.StringVar()\n",
    "    textArea = Text(gui, width = 40, height = 5, font=(\"Arial\", 16))\n",
    "    textArea.grid(row = 0, column = 1, pady = 2)\n",
    "    open_button = Button(gui, text = \"Open text file\", command = open_txt)\n",
    "    open_button.grid(row = 1, column = 1, pady = 2)\n",
    "    check_sentiment = Button(gui, text = \"Check Sentiment\", command=detect_sentiment)\n",
    "    check_sentiment.grid(row = 2, column = 0, pady = 2)\n",
    "    check_ner1 = Button(gui, text = \"Apply Custom NER\", command=ner_prediction)\n",
    "    check_ner1.grid(row = 2, column = 1, pady = 2)\n",
    "    check_ner = Button(gui, text = \"Apply Stanford NER\", command=stanford_ner)\n",
    "    check_ner.grid(row = 2, column = 2, pady = 2)\n",
    "    result_area =  Text(gui, width = 40, height = 5, font=(\"Arial\", 16))\n",
    "    result_area.grid(row = 3, column = 1, pady = 2)\n",
    "    plotgraph1 = Button(gui, text = \"Graph Sentiment prediction\", command = plot_it)\n",
    "    plotgraph1.grid(row = 4, column = 1,pady = 2)\n",
    "    save_button = Button(gui, text = \"Save file\", command= save_file)\n",
    "    save_button.grid(row = 6, column = 1, pady = 2)\n",
    "    clear_button = Button(gui, text = \"Clear\", command= clear_all)\n",
    "    clear_button.grid(row = 7, column = 1, pady = 2)\n",
    "    exit_button = Button(gui, text = \"Exit\", command = exit)\n",
    "    exit_button.grid(row = 8, column = 1, pady = 2)\n",
    "    gui.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4257e57a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef300107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b52119",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
